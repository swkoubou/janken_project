{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e20182b5-cf56-41eb-a933-8be9739708b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2455, 63)\n",
      "X_test shape: (614, 63)\n",
      "Epoch 0, Accuracy: 0.4896\n",
      "Epoch 100, Accuracy: 0.9947\n",
      "Epoch 200, Accuracy: 0.9984\n",
      "Epoch 300, Accuracy: 1.0000\n",
      "Epoch 400, Accuracy: 1.0000\n",
      "Epoch 500, Accuracy: 1.0000\n",
      "Epoch 600, Accuracy: 1.0000\n",
      "Epoch 700, Accuracy: 1.0000\n",
      "Epoch 800, Accuracy: 1.0000\n",
      "Epoch 900, Accuracy: 1.0000\n",
      "モデルの正解率: 1.00\n",
      "モデルを保存しました。\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# ====== 1. 活性化関数 ======\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # 数値的安定性\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "# ====== 2. ネットワークの初期化 ======\n",
    "class DeepNeuralNetwork:\n",
    "    def __init__(self, input_size=40, hidden_sizes=[64, 64, 32, 32, 16], output_size=3, learning_rate=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # 重みとバイアスの初期化（He初期化）\n",
    "        layer_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        self.weights = [np.random.randn(layer_sizes[i], layer_sizes[i+1]) * np.sqrt(2.0/layer_sizes[i]) for i in range(len(layer_sizes) - 1)]\n",
    "        self.biases = [np.zeros((1, layer_sizes[i+1])) for i in range(len(layer_sizes) - 1)]\n",
    "    \n",
    "    # ====== 3. 順伝播 ======\n",
    "    def forward(self, X):\n",
    "        self.activations = [X]  \n",
    "        self.z_values = []  \n",
    "\n",
    "        for i in range(len(self.weights) - 1):  \n",
    "            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]\n",
    "            self.z_values.append(z)\n",
    "            self.activations.append(relu(z))\n",
    "\n",
    "        # 出力層\n",
    "        z = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]\n",
    "        self.z_values.append(z)\n",
    "        self.activations.append(softmax(z))\n",
    "        return self.activations[-1]\n",
    "\n",
    "    # ====== 4. 誤差逆伝播法 ======\n",
    "    def backward(self, X, y):\n",
    "        m = X.shape[0]  \n",
    "        grads_w = [np.zeros_like(w) for w in self.weights]\n",
    "        grads_b = [np.zeros_like(b) for b in self.biases]\n",
    "\n",
    "        # One-hot エンコーディング\n",
    "        y_onehot = np.eye(self.activations[-1].shape[1])[y.astype(int)]  \n",
    "        dz = (self.activations[-1] - y_onehot) / m  \n",
    "\n",
    "        grads_w[-1] = np.dot(self.activations[-2].T, dz)\n",
    "        grads_b[-1] = np.sum(dz, axis=0, keepdims=True)\n",
    "\n",
    "        for i in range(len(self.weights) - 2, -1, -1):\n",
    "            dz = np.dot(dz, self.weights[i+1].T) * relu_derivative(self.z_values[i])\n",
    "            grads_w[i] = np.dot(self.activations[i].T, dz)\n",
    "            grads_b[i] = np.sum(dz, axis=0, keepdims=True)\n",
    "\n",
    "        # パラメータ更新（SGD）\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.learning_rate * grads_w[i]\n",
    "            self.biases[i] -= self.learning_rate * grads_b[i]\n",
    "\n",
    "    # ====== 5. 訓練 ======\n",
    "    def train(self, X, y, epochs=1000, batch_size=32):\n",
    "        history = {'accuracy': []}\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            indices = np.arange(X.shape[0])\n",
    "            np.random.shuffle(indices)\n",
    "            X, y = X[indices], y[indices]\n",
    "    \n",
    "            for i in range(0, X.shape[0], batch_size):\n",
    "                X_batch = X[i:i+batch_size]\n",
    "                y_batch = y[i:i+batch_size]\n",
    "                self.forward(X_batch)\n",
    "                self.backward(X_batch, y_batch)\n",
    "    \n",
    "            predictions = self.predict(X)\n",
    "            acc = np.mean(predictions == y)\n",
    "            history['accuracy'].append(acc)\n",
    "    \n",
    "            if epoch % 100 == 0:\n",
    "                print(f'Epoch {epoch}, Accuracy: {acc:.4f}')\n",
    "        \n",
    "        return history\n",
    "\n",
    "    \n",
    "    # ====== 6. 予測メソッドの追加 ======\n",
    "    def predict(self, X):\n",
    "        probabilities = self.forward(X)\n",
    "        return np.argmax(probabilities, axis=1)\n",
    "\n",
    "# ====== 7. データの準備と学習 ======\n",
    "if __name__ == \"__main__\":\n",
    "    # データを読み込む\n",
    "    df = pd.read_csv(\"data/hand_landmarks.csv\")\n",
    "    \n",
    "    # 特徴量（X）とラベル（y）に分ける\n",
    "    X = df.drop('label', axis=1).values\n",
    "    y = df['label'].values\n",
    "    \n",
    "    # ラベルを数値にエンコード\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "\n",
    "\n",
    "    model = DeepNeuralNetwork(63)\n",
    "    history = model.train(X_train, y_train, epochs=1000, batch_size=32)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'モデルの正解率: {accuracy:.2f}')\n",
    "    \n",
    "    joblib.dump(model, 'hand_gesture_model.pkl')\n",
    "    print('モデルを保存しました。')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c6dca56-abf4-4f14-bd82-e21c537ee0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\2321004\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\2321004\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c645250-ac67-4096-8a81-bf47532286dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2321004\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 239ms/step - accuracy: 0.3736 - loss: 1.1127 - val_accuracy: 0.3906 - val_loss: 1.0915\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.3867 - loss: 1.0878 - val_accuracy: 0.2969 - val_loss: 1.1135\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.3704 - loss: 1.0766 - val_accuracy: 0.3906 - val_loss: 1.0904\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.3640 - loss: 1.0809 - val_accuracy: 0.3750 - val_loss: 1.0914\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.3942 - loss: 1.0834 - val_accuracy: 0.4688 - val_loss: 1.0824\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.4472 - loss: 1.0589 - val_accuracy: 0.4844 - val_loss: 1.0614\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.4979 - loss: 1.0322 - val_accuracy: 0.4844 - val_loss: 1.0368\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.4879 - loss: 1.0007 - val_accuracy: 0.4688 - val_loss: 0.9844\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.5329 - loss: 0.9882 - val_accuracy: 0.5938 - val_loss: 0.9025\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 0.6755 - loss: 0.8615 - val_accuracy: 0.6562 - val_loss: 0.8077\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 0.7073 - loss: 0.7925 - val_accuracy: 0.6875 - val_loss: 0.6934\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.7240 - loss: 0.6607 - val_accuracy: 0.6406 - val_loss: 0.6325\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.7548 - loss: 0.5790 - val_accuracy: 0.7969 - val_loss: 0.5064\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.7852 - loss: 0.4765 - val_accuracy: 0.8125 - val_loss: 0.4477\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.8932 - loss: 0.3679 - val_accuracy: 0.9062 - val_loss: 0.3334\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.9263 - loss: 0.2584 - val_accuracy: 0.8906 - val_loss: 0.3441\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.9408 - loss: 0.2353 - val_accuracy: 0.9219 - val_loss: 0.2906\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.9691 - loss: 0.1593 - val_accuracy: 0.9219 - val_loss: 0.2742\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.9645 - loss: 0.1228 - val_accuracy: 0.9375 - val_loss: 0.2724\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.9642 - loss: 0.1852 - val_accuracy: 0.9375 - val_loss: 0.2424\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9876 - loss: 0.0876 - val_accuracy: 0.9375 - val_loss: 0.2309\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.9729 - loss: 0.0894 - val_accuracy: 0.9531 - val_loss: 0.2588\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.9747 - loss: 0.0826 - val_accuracy: 0.9375 - val_loss: 0.2755\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.9879 - loss: 0.0584 - val_accuracy: 0.9062 - val_loss: 0.3159\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.9900 - loss: 0.0794 - val_accuracy: 0.9375 - val_loss: 0.2513\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.9846 - loss: 0.0596 - val_accuracy: 0.9062 - val_loss: 0.2305\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.9685 - loss: 0.0800 - val_accuracy: 0.9219 - val_loss: 0.2788\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.9783 - loss: 0.0615 - val_accuracy: 0.9531 - val_loss: 0.2426\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.9815 - loss: 0.0424 - val_accuracy: 0.9375 - val_loss: 0.2672\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.9901 - loss: 0.0418 - val_accuracy: 0.9531 - val_loss: 0.2657\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 0.9375 - val_loss: 0.2543\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.9936 - loss: 0.0310 - val_accuracy: 0.9531 - val_loss: 0.2429\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.9986 - loss: 0.0139 - val_accuracy: 0.9375 - val_loss: 0.2947\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.9936 - loss: 0.0185 - val_accuracy: 0.9531 - val_loss: 0.2971\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.9375 - val_loss: 0.2658\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.9981 - loss: 0.0249 - val_accuracy: 0.9531 - val_loss: 0.3033\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9195 - loss: 0.3031\n",
      "CNNモデルのテスト精度: 0.9250\n",
      "CNNモデルを保存しました。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import joblib\n",
    "import sys\n",
    "\n",
    "# ====== 画像の前処理 ======\n",
    "def load_images_from_folder(folder_path, img_size=(64, 64)):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for label in ['0', '1', '2']:  # グー・チョキ・パーを想定\n",
    "        class_dir = os.path.join(folder_path, label)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, img_size)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # RGBに変換（任意）\n",
    "                X.append(img / 255.0)  # 正規化\n",
    "                y.append(int(label))\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# ====== モデル構築 ======\n",
    "def build_cnn_model(input_shape, num_classes=3):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ====== 実行部分 ======\n",
    "if __name__ == \"__main__\":\n",
    "    image_dir = '../create_dataset/images'\n",
    "    X, y = load_images_from_folder(image_dir, img_size=(64, 64))\n",
    "\n",
    "    y_cat = to_categorical(y, num_classes=3)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = build_cnn_model(input_shape=X_train.shape[1:], num_classes=3)\n",
    "\n",
    "    # Early stopping (optional)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    history_cnn = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "    # テスト評価\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    print(f'CNNモデルのテスト精度: {test_acc:.4f}')\n",
    "\n",
    "    # モデル保存（HDF5形式）\n",
    "    model.save('cnn_hand_gesture_model.keras')\n",
    "    print('CNNモデルを保存しました。')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6123876-bd0d-4818-b169-98402475510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 精度の比較\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='MLP train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='MLP val acc')\n",
    "plt.plot(cnn_history.history['accuracy'], label='CNN train acc')\n",
    "plt.plot(cnn_history.history['val_accuracy'], label='CNN val acc')\n",
    "plt.title('モデルの精度比較')\n",
    "plt.xlabel('エポック')\n",
    "plt.ylabel('精度')\n",
    "plt.legend()\n",
    "\n",
    "# 損失の比較\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='MLP train loss')\n",
    "plt.plot(history.history['val_loss'], label='MLP val loss')\n",
    "plt.plot(cnn_history.history['loss'], label='CNN train loss')\n",
    "plt.plot(cnn_history.history['val_loss'], label='CNN val loss')\n",
    "plt.title('モデルの損失比較')\n",
    "plt.xlabel('エポック')\n",
    "plt.ylabel('損失')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf4881a-ee7e-4582-b21f-4bd0282d0ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af6a3db-48b2-4c7b-9efd-0d3b6e76d944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6791df-df8b-4882-84df-87c8f02bc156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
